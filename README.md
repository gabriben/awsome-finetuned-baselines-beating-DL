[![Awesome](https://awesome.re/badge-flat2.svg)](https://awesome.re)

# awsome-non-neural-models

> In so far as a scientific statement speaks about reality, it must be falsifiable: and in so far as it is not falsifiable, it does not speak about reality – *Karl R. Popper, The Logic of Scientific Discovery*

---

## tabular data

[Revisiting Deep Learning Models for Tabular Data](https://openreview.net/pdf?id=i_Q1yrOegLY)  
*Yury Gorishniy, Ivan Rubachev, Valentin Khrulkov, Artem Babenko*  
NeurIPS 2021

[A comparison of neural and non-neural machine learning models for food safety risk prediction with European Union RASFF data](https://www.sciencedirect.com/science/article/pii/S0956713521008355)  
*Alberto Nogales, Rodrigo Díaz-Morón and Álvaro J.García-Tejedor*  
Food Control 2022

[Why do tree-based models still outperform deep
learning on tabular data?](https://arxiv.org/pdf/2207.08815.pdf)  
*Léo Grinsztajn, Edouard Oyallon, Gaël Varoquaux*  
arXiv 2022

## time series

[Do We Really Need Deep Learning Models for Time Series Forecasting?](https://arxiv.org/pdf/2101.02118.pdf)  
*Shereen Elsayed, Daniela Thyssens, Ahmed Rashed, Hadi Samer Jomaa, and Lars Schmidt-Thieme*  
arXiv 2021

## text classification

[On the cost-effectiveness of neural and non-neural approaches and representations for text classification: A comprehensive comparative study](https://www.sciencedirect.com/science/article/abs/pii/S0306457320309705)  
*Washington Cunha, Vítor Mangaravite, Christian Gomes, Sérgio Canuto, Elaine Resende, Cecilia Nascimento, Felipe Viegas, Celso França, Wellington Santos Martins, Jussara M. Almeida, Thierson Rosa, Leonardo Rocha, Marcos André Gonçalves*  
Information Processing & Management 2021

##  Natural Language Generation

[Non-neural Models Matter:
A Re-evaluation of Neural Referring Expression Generation Systems](https://arxiv.org/pdf/2203.08274.pdf)  
*Fahime Same, Guanyi Chen and Kees van Deemter*  
arXiv 2022

## recommendation (collaborative filtering)

[On the Difficulty of Evaluating Baselines](https://arxiv.org/pdf/1905.01395v1.pdf)  
*Steffen Rendle, Li Zhang, Yehuda Koren*  
arXiv 2019

[Why Are Deep Learning Models Not Consistently Winning Recommender Systems Competitions Yet?: A Position Paper](https://www.researchgate.net/profile/Dietmar-Jannach/publication/345464903_Why_Are_Deep_Learning_Models_Not_Consistently_Winning_Recommender_Systems_Competitions_Yet_A_Position_Paper/links/608598ea8ea909241e261562/Why-Are-Deep-Learning-Models-Not-Consistently-Winning-Recommender-Systems-Competitions-Yet-A-Position-Paper.pdf)  
*Dietmar Jannach, Gabriel Moreira, Even Oldridge*  
RecSys Challenge 2020

[Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches](https://arxiv.org/pdf/1907.06902.pdf)  
*Maurizio Ferrari Dacrema, Paolo Cremonesi, Dietmar Jannach*  
arXiv 2019

[Revisiting the Performance of iALS on Item Recommendation Benchmarks](https://dl.acm.org/doi/10.1145/3523227.3548486)  
*Steffen Rendle, Walid Krichene, Li Zhang, Yehuda Koren*  
RecSys 2022

## learning to rank

[Critically Examining the “Neural Hype”: Weak Baselines and the Additivity of Effectiveness Gains from Neural Ranking Models](https://arxiv.org/pdf/1904.09171.pdf)  
*Wei Yang, Kuang Lu, Peilin Yang, and Jimmy Lin*  
arXiv 2019

---

# still neural but simple-beats-basline

## metric learning

[A Metric Learning Reality Check](https://arxiv.org/pdf/2003.08505.pdf)  
*Kevin Musgrave, Serge Belongie, Ser-Nam Li*  
arXiv 2020
